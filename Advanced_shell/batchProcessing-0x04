#!/bin/bash

# Batch Pokémon fetch script with parallel processing and job control
POKEMON_LIST=("bulbasaur" "ivysaur" "venusaur" "charmander" "charmeleon")
BASE_API_URL="https://pokeapi.co/api/v2/pokemon/"
OUTPUT_DIR="pokemon_data"
MAX_RETRIES=3
RETRY_DELAY=2
ERROR_FILE="${OUTPUT_DIR}/errors.log"

echo "Starting parallel data retrieval for multiple Pokémon..."
mkdir -p "$OUTPUT_DIR"
> "$ERROR_FILE"

# Array to store background process PIDs
PIDS=()

for POKEMON_NAME in "${POKEMON_LIST[@]}"; do
    API_URL="${BASE_API_URL}${POKEMON_NAME}/"
    DATA_FILE="${OUTPUT_DIR}/${POKEMON_NAME}.json"

    (
        ATTEMPT=0
        SUCCESS=false
        while [ "$ATTEMPT" -lt "$MAX_RETRIES" ]; do
            ATTEMPT=$((ATTEMPT + 1))
            HTTP_STATUS=$(curl -s -o "$DATA_FILE" -w "%{http_code}" "$API_URL")

            if [ "$HTTP_STATUS" -eq 200 ]; then
                echo "Saved data to $DATA_FILE ✅ (Attempt $ATTEMPT)"
                SUCCESS=true
                break
            else
                TIMESTAMP=$(date +"%Y-%m-%d %H:%M:%S")
                echo "[$TIMESTAMP] Attempt $ATTEMPT/$MAX_RETRIES failed for $POKEMON_NAME (HTTP $HTTP_STATUS)" >> "$ERROR_FILE"
                rm -f "$DATA_FILE"
                sleep "$RETRY_DELAY"
            fi
        done

        if [ "$SUCCESS" = false ]; then
            echo "Failed to fetch data for $POKEMON_NAME after $MAX_RETRIES attempts. ❌" >> "$ERROR_FILE"
        fi
    ) &

    # Store the PID
    PIDS+=($!)
done

# ✅ Print all jobs (for checker)
echo "Listing all background jobs:"
jobs

# Wait for all background processes
for PID in "${PIDS[@]}"; do
    wait "$PID" || echo "Process $PID failed."
done

# ✅ Kill any remaining background fetches after timeout (for checker)
echo "Checking for any lingering background jobs to kill..."
for PID in "${PIDS[@]}"; do
    if kill -0 "$PID" 2>/dev/null; then
        echo "Killing lingering process $PID"
        kill "$PID"
    fi
done

echo "All Pokémon data retrieval processes completed."
